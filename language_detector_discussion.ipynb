{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple language detector tools available in the market, naming only 'langdetect', 'langid', 'cld3' or 'fasttext'. Moreover, there are plenty of pretrained LLMs that are available at Hugging Face, most of them basing on BERT or RoBERTa. Due to the large number of out of the box solutions, some criterion for choosing the desired solution is needed. For that reason, the most natural criterion is the accuracy of the model. However, the performance of the model may differ, depending on the number of the languages, as well as the text length. For example, the newest version of 'fastext' supports 217 languages, which is current state of the art. However, depending on the usecase smaller set of languages might be sufficient. Other important factor is the inference time, as well as the model size. The inference time is important, especially when the model is used in the production environment, where the speed of the model is crucial. The model size is also important, as the model may be used in the mobile application, where the size of the model is important.\n",
    "\n",
    "Below, some existing benchmarks are presented, which may be useful for choosing the desired model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing accuracy of different language detectors on different datasets\n",
    "\n",
    "The charts present the accuracy of different language detectors on different datasets. The accuracy is measured as the percentage of correctly classified languages. The considered models are 'fasttext', 'cld3', 'langid', 'LSTM-LID' and 'xlm-roberta'. The datasets are TweetLID14, OpenSubtitles2018, Language Detection, Tatoeba and Papluca language identification. The results are adopted from https://medium.com/besedo-engineering/language-identification-for-very-short-texts-a-review-c9f2756773ad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![benchmark](images/accuracy_benchmark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing inference time of different language detectors on Tatoeba dataset\n",
    "\n",
    "Similar benchmark can be made for the inference time. The inference is measured on the Tatoeba dataset. The results are adopted from https://medium.com/besedo-engineering/language-identification-for-very-short-texts-a-review-c9f2756773ad.\n",
    "\n",
    "![benchmark](images/inference_benchmark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Considering above benchmarks, the 'fasttext' model seems to be the most general choice, as it has the highest accuracy (although for some usecases with shorter texts, different models might by more appropriate) and the lowest inference time. The major drawback of the 'fasttext' model is the model size, however there exists also smaller version of the model, which takes 917kB only and can be used on the edge-devices as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
